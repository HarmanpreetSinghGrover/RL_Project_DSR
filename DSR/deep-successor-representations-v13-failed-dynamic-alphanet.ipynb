{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I implement Deep Successor Reinforcement Learning by Tejas D. Kulkarni, Ardavan Saeedi, Simanta Gautam, Samuel J. Gershman. ([link](https://arxiv.org/abs/1606.02396))\n",
    "\n",
    "v12 -  attempt on pong game\n",
    "\n",
    "To do:\n",
    "- include visdom for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# if gpu is to be used\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Boxing-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 80\n",
    "IMG_WIDTH = 80\n",
    "\n",
    "def get_screen(env):\n",
    "    k = env.render(mode='rgb_array')\n",
    "    k = resize(k, (IMG_HEIGHT, IMG_WIDTH), anti_aliasing=False)\n",
    "    k = torch.Tensor(k)\n",
    "    k = k.permute(2,1,0).unsqueeze(0)\n",
    "    k = k.to(device)\n",
    "    return k\n",
    "\n",
    "# def state2screen(state):\n",
    "#     k = resize(state, (IMG_HEIGHT, IMG_WIDTH), anti_aliasing=False)\n",
    "#     k = torch.Tensor(k)\n",
    "#     k = k.permute(2,1,0).unsqueeze(0)\n",
    "#     k = k.to(device)\n",
    "#     return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 160, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f274f2a4c88>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gym_minigrid.envs import EmptyEnv\n",
    "\n",
    "env_name = 'PongDeterministic-v4'\n",
    "# env_name='MiniGrid-Empty-Random-5x5-v0'\n",
    "# env = EmptyEnv()\n",
    "env = gym.make(env_name)\n",
    "env.reset()\n",
    "k = env.render(mode='rgb_array')\n",
    "plt.imshow(env.render(mode='rgb_array'));plt.show()\n",
    "print(k.shape)\n",
    "plt.imshow(resize(k, (IMG_HEIGHT, IMG_WIDTH), anti_aliasing=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action =  5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 160, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f274f1fada0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = env.action_space.sample(); print('action = ', a)\n",
    "env.step(a)\n",
    "k = env.render(mode='rgb_array')\n",
    "plt.imshow(env.render(mode='rgb_array'));plt.show()\n",
    "print(k.shape)\n",
    "plt.imshow(resize(k, (IMG_HEIGHT, IMG_WIDTH), anti_aliasing=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing neural network in torch for FA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHI_SIZE = 512\n",
    "\n",
    "class thetaNet(nn.Module):\n",
    "\n",
    "    def __init__(self, h=80, w=80, outputs=PHI_SIZE):\n",
    "        super(thetaNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * 64\n",
    "        \n",
    "        self.head = nn.Linear(linear_input_size, outputs)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)));\n",
    "        return self.head(x.view(x.size(0), -1))\n",
    "    \n",
    "class theta2Net(nn.Module): # decoder for thetaNet\n",
    "    def __init__(self, h=80, w=80, inputs=PHI_SIZE):\n",
    "        super(theta2Net, self).__init__()\n",
    "        \n",
    "        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        self.convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        self.convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = self.convw * self.convh * 64\n",
    "        \n",
    "        self.linear = nn.Linear(inputs, linear_input_size)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.deconv1 = nn.ConvTranspose2d(64, 64, kernel_size=5, stride=2, output_padding=0)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.deconv2 = nn.ConvTranspose2d(64, 32, kernel_size=5, stride=2, output_padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.deconv3 = nn.ConvTranspose2d(32, 3, kernel_size=5, stride=2, output_padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear(x))\n",
    "#         import pdb; pdb.set_trace()\n",
    "        x = x.view(x.size(0), 64, self.convh, self.convw)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(self.bn2(self.deconv1(x)))\n",
    "        x = F.relu(self.bn3(self.deconv2(x)))\n",
    "        x = self.deconv3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class alphaNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_size=PHI_SIZE, mid_size=256, actions=3):\n",
    "        super(alphaNet, self).__init__()\n",
    "        self.actions = actions\n",
    "        for i in range(self.actions):\n",
    "            code = 'self.head' + str(i+1) + '1 = nn.Linear(in_size, in_size)'\n",
    "            exec(code)\n",
    "            code = 'self.head' + str(i+1) + '2 = nn.Linear(in_size, mid_size)'\n",
    "            exec(code)\n",
    "            code = 'self.head' + str(i+1) + '3 = nn.Linear(mid_size, in_size)'\n",
    "            exec(code)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        for i in range(self.actions):\n",
    "            code = 'x' + str(i+1) + ' = self.head' + str(i+1) + '3(F.relu(self.head' + str(i+1) + \\\n",
    "                    '2(F.relu(self.head' + str(i+1) + '1(x)))))'\n",
    "            exec(code)\n",
    "            \n",
    "        exec('y = x1')\n",
    "        for i in range(1, self.actions):\n",
    "            code = 'y = torch.cat((y, x' + str(i+1) + '), 1)'\n",
    "            exec(code)\n",
    "            \n",
    "        exec('return y.view(y.size(0), self.actions, -1)')\n",
    "    \n",
    "class wNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_size=PHI_SIZE):\n",
    "        super(wNet, self).__init__()\n",
    "        self.head = nn.Linear(in_size, 1)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        return self.head(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing replay memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward', 'done'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "        self.ready = False\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        self.ready = True\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        if(len(self.memory) < batch_size):\n",
    "            return random.sample(self.memory, len(self.memory)), len(self.memory)\n",
    "        return random.sample(self.memory, batch_size), batch_size\n",
    "    \n",
    "    def is_ready(self):\n",
    "        return len(self.memory)>2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up networks and memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnet = thetaNet().to(device); tnet2 = theta2Net().to(device);\n",
    "anet = alphaNet(actions=env.action_space.n).to(device); wnet = wNet().to(device); \n",
    "anet_target = alphaNet(actions=env.action_space.n).to(device)\n",
    "anet_target.load_state_dict(anet.state_dict()); anet_target.eval()\n",
    "\n",
    "memory = ReplayMemory(50000)\n",
    "memory_win = ReplayMemory(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating select action method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_done = 0\n",
    "BATCH_SIZE = 8000\n",
    "GAMMA = 0.99\n",
    "EPS_START = 1\n",
    "EPS_END = 0.01\n",
    "EPS_DECAY = 2000\n",
    "TARGET_UPDATE = 20\n",
    "eps_threshold = 1\n",
    "\n",
    "def select_action(phi, w, greedy=False):\n",
    "    if(greedy):\n",
    "        aout = anet(phi)\n",
    "        return aout.matmul(w).max(1)[1]\n",
    "    global steps_done\n",
    "    global eps_threshold\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            aout = anet(phi)\n",
    "            return aout.matmul(w).max(1)[1] #maybe add .view(1,1)\n",
    "    else:\n",
    "#         import pdb; pdb.set_trace();\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()\n",
    "loss_a = nn.MSELoss()\n",
    "loss_b = nn.MSELoss()\n",
    "L_r_vec = []\n",
    "L_m_vec = []\n",
    "L_a_vec = []\n",
    "\n",
    "tw_params = list(tnet.parameters()) + list(tnet2.parameters()) + list(wnet.parameters())\n",
    "optimizer_tw = optim.Adam(tw_params, lr=50e-5)\n",
    "optimizer_a = optim.Adam(anet.parameters(), lr=25e-5)\n",
    "\n",
    "def optimize_model():\n",
    "    if (len(memory) < BATCH_SIZE) or (not memory_win.is_ready()):\n",
    "        return\n",
    "    \n",
    "    # Training reward and reconstruction branches\n",
    "    if(np.random.rand()>0.8): # winning samples 20% times this runs\n",
    "        transitions, bs = memory_win.sample(BATCH_SIZE)\n",
    "        \n",
    "    else: # intermediate samples\n",
    "        transitions, bs = memory.sample(BATCH_SIZE)\n",
    "        \n",
    "    batch = Transition(*zip(*transitions))\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "    nstate_batch = torch.cat(batch.next_state)\n",
    "    action_max = anet(tnet(state_batch)).matmul(wnet.head.weight.data.view(-1,1)).max(1)[1]\n",
    "    next_state_ests = anet_target(tnet(nstate_batch))[torch.arange(0, bs),action_max.squeeze(),:]\n",
    "    \n",
    "    L_r = F.smooth_l1_loss(reward_batch, wnet(tnet(nstate_batch)).squeeze(1))\n",
    "    L_a = loss_a(state_batch, tnet2(tnet(state_batch))) + loss_b(nstate_batch, tnet2(tnet(nstate_batch)))\n",
    "    L_r_vec.append(L_r.item())\n",
    "    L_a_vec.append(L_a.item())\n",
    "    L_ra = L_a + L_r\n",
    "    optimizer_tw.zero_grad()\n",
    "    L_ra.backward()\n",
    "    optimizer_tw.step()\n",
    "    \n",
    "    \n",
    "    # Training the SR branch\n",
    "    transitions, bs = memory.sample(32)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "    nstate_batch = torch.cat(batch.next_state)\n",
    "    done_batch = torch.cat(batch.done)\n",
    "    \n",
    "    \n",
    "    # Create a non-final state mask\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s==0,\n",
    "                                          batch.done)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for en, s in enumerate(batch.next_state)\n",
    "                                                if batch.done[en]==0])\n",
    "    action_max = anet(tnet(non_final_next_states)).matmul(wnet.head.weight.data.view(-1,1)).max(1)[1]\n",
    "    # initialize them to values we need for terminal states\n",
    "    next_state_ests = tnet(nstate_batch) \n",
    "    # replace the values of non-terminal states based on update equation\n",
    "    \n",
    "    next_state_ests[non_final_mask] = anet_target(tnet(non_final_next_states))[torch.arange(0, non_final_mask.sum()),\n",
    "                                                                               action_max.squeeze(),:]\n",
    "    U_observed = anet(tnet(state_batch))[torch.arange(0, bs),action_batch.squeeze(),:]\n",
    "    U_estimated = tnet(state_batch) + GAMMA * next_state_ests\n",
    "    L_m = loss(U_observed, U_estimated)\n",
    "    L_m_vec.append(L_m.item())\n",
    "    optimizer_a.zero_grad()\n",
    "    L_m.backward()\n",
    "    optimizer_a.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_test = gym.make(env_name)\n",
    "def evaluate(no_seeds=10):\n",
    "    r_vec = []\n",
    "    for i in range(no_seeds):\n",
    "        env_test.seed(i)\n",
    "        env_test.reset()\n",
    "        Rt = 0\n",
    "        for timesteps in count():\n",
    "            # choose greedy action\n",
    "            action = select_action(tnet(get_screen(env_test)), wnet.head.weight.data.view(-1,1), greedy=True)\n",
    "            _, R, done, _ = env_test.step(action.item())\n",
    "            Rt = R + Rt\n",
    "            if(done):\n",
    "                r_vec.append(R)\n",
    "                break\n",
    "                \n",
    "    return np.mean(r_vec), np.std(r_vec) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializations: Line 1\n",
    "num_episodes = 300 # CHANGE\n",
    "n_actions = 3\n",
    "R_eps = []\n",
    "ed = []; eps_vec = [];\n",
    "actions = []\n",
    "eval_r_mean = []; eval_r_std = []\n",
    "EVAL_INTERVAL = 1000\n",
    "\n",
    "#Setting seeds\n",
    "torch.manual_seed(0); np.random.seed(0)\n",
    "env.seed(0)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'matmul'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-07fefad0449c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Select an action: Line 6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-2d600a3bd942>\u001b[0m in \u001b[0;36mselect_action\u001b[0;34m(phi, w, greedy)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0maout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0maout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#maybe add .view(1,1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#         import pdb; pdb.set_trace();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'matmul'"
     ]
    }
   ],
   "source": [
    "global i_episode\n",
    "for i_episode in tqdm(range(num_episodes)): # Line 2\n",
    "    R = 0\n",
    "    if(BATCH_SIZE>2):\n",
    "        BATCH_SIZE = BATCH_SIZE // 2\n",
    "    \n",
    "    # Initialize the environment and state: Line 3\n",
    "#     env.seed(0)\n",
    "    env.reset() # <TODO: random initial location>\n",
    "    state = get_screen(env)\n",
    "#     state = env.reset()\n",
    "#     state = state2screen(state)\n",
    "    for t in count(): # Line 4\n",
    "#         print(t, action)\n",
    "        \n",
    "        # Find abstracted states: Line 5\n",
    "        phi = tnet(state)\n",
    "        \n",
    "        # Select an action: Line 6\n",
    "        action = select_action(phi, wnet.head.weight.data.view(-1,1))\n",
    "        actions.append(action.item())\n",
    "        \n",
    "        # Perform an action: Line 7\n",
    "        _, reward, done, _ = env.step(action.item())\n",
    "#         next_state = state2screen(next_state)\n",
    "        done = torch.tensor([done], device=device)\n",
    "        if(reward > 0):\n",
    "            reward = 1\n",
    "        R = R + reward\n",
    "        reward = torch.tensor([reward], device=device).float()\n",
    "        next_state = get_screen(env)\n",
    "        \n",
    "        # Store the transition in memory: Line 8\n",
    "        if(reward<=0):\n",
    "            memory.push(state, action, next_state, reward, done)\n",
    "        else:\n",
    "            memory_win.push(state, action, next_state, reward, done)\n",
    "            memory.push(state, action, next_state, reward, done)  \n",
    "            print(reward)\n",
    "            ed.append(t+1)\n",
    "            R_eps.append(R)\n",
    "            eps_vec.append(eps_threshold)\n",
    "            break\n",
    "            \n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Lines 9 - 11\n",
    "        optimize_model() # TODO\n",
    "        \n",
    "        # Additional tracking\n",
    "        if done:\n",
    "            ed.append(t+1)\n",
    "            R_eps.append(R)\n",
    "            eps_vec.append(eps_threshold)\n",
    "            break\n",
    "            \n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        anet_target.load_state_dict(anet.state_dict())\n",
    "        \n",
    "    if eps_threshold < 1.1*EPS_END:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-9-2d600a3bd942>\u001b[0m(23)\u001b[0;36mselect_action\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     21 \u001b[0;31m        \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     22 \u001b[0;31m            \u001b[0maout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 23 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0maout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#maybe add .view(1,1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     24 \u001b[0;31m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     25 \u001b[0;31m\u001b[0;31m#         import pdb; pdb.set_trace();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> phi\n",
      "tensor([[ 0.0778, -0.2087, -0.2598, -0.2211, -0.8299, -0.5966, -0.7539,  0.5160,\n",
      "          0.9272, -0.6778,  0.2329,  0.3536, -0.3342,  0.0357,  0.7510, -0.0300,\n",
      "         -0.3704, -0.0610,  0.5968, -0.3895,  0.3658,  0.0123, -0.4195,  0.4102,\n",
      "          0.6948,  0.4565,  0.3027,  0.2559,  0.0725,  0.8173, -0.1579, -0.4101,\n",
      "         -0.1635,  0.2421, -0.5406, -0.3133,  0.3528,  0.5353,  0.4598, -0.7011,\n",
      "          0.6387, -0.0545, -0.5731, -0.2426, -0.8827, -0.3508, -0.3403,  0.7566,\n",
      "         -0.1632, -0.9502, -0.0859, -0.0963, -0.0128,  0.0325,  0.4084,  0.0089,\n",
      "          0.3204, -0.0378, -0.3072,  0.7156, -0.0822, -0.4300, -0.2985,  0.1763,\n",
      "          0.2109, -0.6657, -0.1391, -0.2024, -0.1024, -0.0951,  0.2945,  0.3869,\n",
      "         -0.0331,  0.6128,  0.3388,  0.9700,  0.3549,  0.0566,  1.3325,  0.9800,\n",
      "          0.1040,  0.2410, -0.0164,  0.1452,  0.1076,  0.1728,  0.6815, -0.0452,\n",
      "         -0.2951, -0.8404, -0.3026,  0.0862,  0.0348,  0.5569, -0.0502,  0.1449,\n",
      "         -0.5146, -0.1133,  0.2076,  0.6856, -0.2432,  0.0715,  0.5302,  0.9362,\n",
      "         -0.1948,  0.7241,  0.2471,  0.1376, -0.2904, -0.4100, -0.1597, -0.3049,\n",
      "          0.0668, -0.4575, -0.2567,  0.2381, -0.2096,  1.0044,  0.0548,  0.0506,\n",
      "         -0.1777, -0.1244, -0.1394,  0.3695, -0.2998, -0.1771,  0.3897,  0.1001,\n",
      "         -0.2038, -0.3724, -0.1574,  0.3053,  0.0197,  0.2231, -0.4131,  0.3962,\n",
      "          0.1431, -0.0106,  0.5501,  0.2675, -0.4224, -0.1015,  0.2677,  0.8345,\n",
      "         -0.2752,  0.0116,  0.3835, -0.7387,  0.7229,  0.4188,  0.1389, -0.4428,\n",
      "         -0.4750, -0.6951, -0.0713,  0.0554, -0.2286,  0.4276, -0.5384,  0.3097,\n",
      "         -0.5062, -0.1605,  0.3281,  0.2365,  0.2178, -0.1705,  0.3556,  0.0868,\n",
      "         -0.2893,  0.1696, -0.4342,  0.0255, -0.0623,  0.4497,  0.2385, -0.2711,\n",
      "         -0.7866, -0.5424, -0.0658, -0.8001, -0.0141, -0.0600,  0.1793,  0.1823,\n",
      "         -0.0479, -0.5579,  0.1874,  0.1893, -0.3194, -0.5857,  0.3819,  0.4476,\n",
      "          0.4162,  0.2301, -0.0429, -0.0623,  0.3310, -0.1158, -0.6951, -0.5922,\n",
      "         -0.2975, -0.2123,  0.1614, -0.3204, -0.6626, -0.2323,  0.0708,  0.3002,\n",
      "         -0.2479,  0.1895, -0.3952,  0.2235, -0.1161, -0.1409, -0.1820, -0.1309,\n",
      "          0.2335,  0.1986, -0.0372,  0.3573, -0.0985,  0.5224, -0.5059, -0.4445,\n",
      "         -0.7633, -0.2354, -0.6788,  0.1577,  1.1037, -0.4903, -0.5947,  0.0914,\n",
      "         -0.0927, -0.0556, -0.1751,  0.1249, -0.4637,  0.3134,  0.5876,  0.3557,\n",
      "          0.1567, -0.1065,  0.1661, -0.1335,  0.0278, -0.0509,  0.1911,  0.0720,\n",
      "         -0.5964, -0.2139, -0.3403,  0.1985,  0.0191, -0.4376,  0.5998, -0.1950,\n",
      "         -0.4865, -0.2620, -0.0021, -0.3964,  0.0291,  0.3434, -0.2338,  0.3728,\n",
      "          0.3179, -0.2588, -0.4202,  0.0313,  0.0350,  0.3652,  0.3603, -0.0382,\n",
      "         -0.7170,  0.4533,  0.2521,  0.3459, -0.3850,  0.0606, -0.1894,  0.0806,\n",
      "          0.4029, -0.1350,  0.4830, -0.0754, -0.0598,  0.0094, -0.0510,  0.3297,\n",
      "         -0.4944, -0.0238,  0.3685,  0.1954, -0.1758, -0.1144,  0.7541,  0.2727,\n",
      "          0.1317,  0.1728,  0.0305,  0.4663,  0.7235, -0.0161,  0.2862, -0.5141,\n",
      "          0.3305,  0.2635,  0.3268, -0.1944, -0.2905, -0.3448,  0.4055,  0.0890,\n",
      "         -0.4516, -0.0289, -0.0242, -0.3573,  0.4096, -0.7490,  0.6310, -0.3895,\n",
      "          0.3511,  0.3059, -0.3353, -0.3700,  0.0106, -0.1772, -0.6305,  0.2968,\n",
      "         -0.1061, -0.2381, -0.4089,  0.5921, -0.2685,  0.7005,  0.0945,  0.2936,\n",
      "         -0.1287,  0.3663, -0.5036,  0.2324, -0.7013,  0.3689,  0.1622, -0.5103,\n",
      "         -0.0549,  0.5285,  0.6371,  1.0818, -0.8909, -0.1209, -0.4344,  0.1274,\n",
      "         -0.6935,  0.0454, -0.2442, -0.4725,  0.2275,  0.7855,  0.3767,  0.0645,\n",
      "          0.4454, -0.6968,  0.0296, -0.2716, -0.1777, -0.4368, -0.1823, -0.3062,\n",
      "         -0.2053, -0.2506,  0.3821, -0.7704,  0.4351, -0.1684, -0.6517,  0.1926,\n",
      "          0.7374, -0.2796,  0.4812,  0.2777,  0.2665,  0.6429,  0.1244,  0.4826,\n",
      "          0.2152,  0.7399, -0.2369, -0.6352,  0.7067,  0.3529,  0.2310,  0.4261,\n",
      "         -0.5982,  0.0104,  0.3237,  0.2654,  0.2617,  0.3574, -0.0868,  0.7560,\n",
      "         -0.2574,  0.3029, -1.0580,  0.8634,  0.0155,  0.4829, -0.1421, -0.3407,\n",
      "         -0.2889, -0.0741, -0.0613,  0.0259, -0.0499,  0.1557,  0.0990, -0.1401,\n",
      "         -0.5438, -0.5069, -0.7173,  0.4816,  0.0188,  0.2738,  0.3770,  0.6843,\n",
      "         -0.4561, -0.0516, -0.2938,  0.3285,  0.1159,  0.2431,  0.1820,  0.4459,\n",
      "          0.2119, -0.2888, -0.1098, -0.4696, -0.0540, -0.4900,  0.1549, -0.0162,\n",
      "         -0.0988,  0.2653, -0.1005, -0.3050,  0.2450,  0.1174, -0.1260, -0.0270,\n",
      "          0.1278, -0.1562, -0.0925, -0.5353, -0.1035, -0.4917,  0.1525,  0.5224,\n",
      "          0.0083, -0.6885, -0.7772, -0.5802,  1.0149, -0.3000, -0.4776, -0.1954,\n",
      "         -0.1146, -0.1117, -0.0112,  0.0726, -0.6154, -0.2172, -0.0986,  0.2255,\n",
      "         -0.0204, -0.1367, -0.2089, -0.8979, -0.2131, -0.7524,  0.0238,  0.3958,\n",
      "          0.2402, -0.5149,  0.2295, -0.4108,  0.0516,  0.4474, -0.2467, -0.0394,\n",
      "         -0.0078, -0.9360, -0.1748, -0.2488, -0.2794, -0.6238,  0.0369, -0.7261,\n",
      "         -0.0172, -0.1123,  0.2364, -0.3126, -0.2710, -0.3431, -0.3205,  0.2249,\n",
      "         -0.3874, -0.3174,  0.2617,  0.0893,  1.3550,  0.2146, -0.6475, -0.3312]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "ipdb> phi.shape\n",
      "torch.Size([1, 512])\n",
      "ipdb> anet(phi).shape\n",
      "*** AttributeError: 'NoneType' object has no attribute 'shape'\n",
      "ipdb> anet(phi)\n",
      "--KeyboardInterrupt--\n",
      "ipdb> quit\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(14,6))\n",
    "# plt.errorbar(np.arange(len(eval_r_mean)), eval_r_mean, eval_r_std, linestyle='None', marker='^')\n",
    "# plt.title('evaluation rewards as training progresses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results():\n",
    "    plt.figure(figsize=(18,9))\n",
    "    plt.subplot(3,3,1); plt.plot(ed); plt.title('ep_length');\n",
    "    plt.subplot(3,3,2); plt.plot(R_eps); plt.title('R'); \n",
    "    plt.subplot(3,3,3); plt.plot(eps_vec); plt.title('eps values'); \n",
    "    plt.subplot(3,3,4); plt.plot(L_r_vec[:]); plt.title('reward loss'); \n",
    "    plt.subplot(3,3,5); plt.plot(L_m_vec[:]); plt.title('SR loss'); \n",
    "    plt.subplot(3,3,6); plt.plot(L_a_vec[:]); plt.title('reconstruction loss'); \n",
    "    plt.subplot(3,3,7); plt.plot(np.cumsum(ed)); plt.title('cumm episode steps'); plt.show()\n",
    "\n",
    "visualize_results()\n",
    "print('number of wins: ', len(memory_win))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "plt.plot(actions); plt.title('sanity check for actions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_samples_from_memory(memory, batchsize=4):\n",
    "    k = memory.sample(4)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    for i in range(4):\n",
    "        plt.subplot(2,2,i+1)\n",
    "        plt.imshow(k[0][i].next_state.cpu().squeeze(0).permute(1,2,0).numpy())\n",
    "        plt.title('R = {}'.format(k[0][i].reward.cpu().numpy()[0]))\n",
    "    plt.show()\n",
    "    \n",
    "visualize_samples_from_memory(memory)\n",
    "visualize_samples_from_memory(memory_win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_qvalues(i):\n",
    "    state_matrix = torch.load('state_matrix_3x3.pt')\n",
    "#     print(anet(tnet(state_matrix[i,:,:,:].unsqueeze(0))).shape)\n",
    "    print(anet(tnet(state_matrix[i,:,:,:].unsqueeze(0))).squeeze(0).matmul(wnet.head.weight.data.squeeze(0)))\n",
    "\n",
    "find_qvalues(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def sanity_check():\n",
    "#     env.seed(0)\n",
    "    env.reset()\n",
    "    eps_threshold = 1\n",
    "    iterations = 15\n",
    "    plt.figure(figsize=(15,10), dpi=200)\n",
    "    R = 0\n",
    "    for i in range(iterations):\n",
    "        plt.subplot(5,6,2*i+1)\n",
    "        plt.imshow(env.render(mode='rgb_array')); \n",
    "        plt.subplot(5,6,2*i+2)\n",
    "        plt.imshow(tnet2(tnet(get_screen(env))).cpu().squeeze(0).permute(1,2,0).detach().numpy());\n",
    "        state = get_screen(env)\n",
    "        plt.title('R = {0:.2f}, i = {1:.0f}'.format(wnet(tnet(state)).detach().cpu().numpy()[0,0], i))\n",
    "        action = select_action(tnet(state), wnet.head.weight.data.view(-1,1), greedy=True)\n",
    "#         action = np.random.randint(low=0, high=3)\n",
    "        print('iteration: {}, action: {}, R: {}, i: {}'.format(i, action.item(), R, i))\n",
    "        print(wnet(tnet(state)))\n",
    "#         print(anet(tnet(state)).matmul(wnet.head.weight.data.view(-1,1)).detach().cpu().numpy())\n",
    "        _, R, done, _ = env.step(action)\n",
    "        if(done):\n",
    "            print('SOLVED!')\n",
    "            break\n",
    "    plt.show()\n",
    "sanity_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = evaluate(10)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(env.render(mode='rgb_array'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models(label=\"tmp\"):\n",
    "    torch.save(tnet.state_dict(), label+\"tnet\"+\".pt\")\n",
    "    torch.save(tnet2.state_dict(), label+\"tnet2\"+\".pt\")\n",
    "    torch.save(anet.state_dict(), label+\"anet\"+\".pt\")\n",
    "    torch.save(wnet.state_dict(), label+\"wnet\"+\".pt\")\n",
    "    \n",
    "# save_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_sanity_check():\n",
    "    state_matrix = torch.load('state_matrix_3x3.pt')\n",
    "    reward_est = wnet(tnet(state_matrix)).squeeze(1)\n",
    "    reward_est = reward_est.detach().cpu().numpy()\n",
    "    error_0 = np.mean(np.abs(reward_est[:32]-np.zeros(32)))\n",
    "    error_1 = np.mean(np.abs(reward_est[34:]-np.ones(2)))\n",
    "    print('0-reward error: {0:2.3f}, 1-reward error: {1:2.3f}'.format(error_0, error_1))\n",
    "    print('reward estimates: ', reward_est)\n",
    "    \n",
    "reward_sanity_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warnings.simplefilter(\"once\")\n",
    "def reconstruction_sanity_check():\n",
    "    state_matrix = torch.load('state_matrix_3x3.pt')\n",
    "    state_r = tnet2(tnet(state_matrix))\n",
    "    plt.figure(figsize=(18,18), dpi=100)\n",
    "    for i in range(36):\n",
    "        plt.subplot(12,8,2*i+1)\n",
    "        plt.imshow(state_matrix.detach().cpu()[i,:,:,:].squeeze(0).permute(1,2,0).numpy())\n",
    "        plt.subplot(12,8,2*i+2)\n",
    "        plt.imshow(state_r.detach().cpu()[i,:,:,:].squeeze(0).permute(1,2,0).numpy())\n",
    "    plt.show()\n",
    "    \n",
    "reconstruction_sanity_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def SR_sanity_check(): # this needs to fail, would be correct for incorrect implementations\n",
    "    \n",
    "    state_matrix = torch.load('state_matrix_3x3.pt')\n",
    "    \n",
    "    phi = tnet(state_matrix)\n",
    "    exp1 = GAMMA * phi[35,:].detach().cpu().numpy()\n",
    "    exp2 = GAMMA * phi[34,:].detach().cpu().numpy()\n",
    "    \n",
    "    M = anet(tnet(state_matrix))\n",
    "    est1 = M[23,2,:].detach().cpu().numpy()\n",
    "    est2 = M[30,2,:].detach().cpu().numpy()\n",
    "    \n",
    "    plt.figure(figsize=(18,6))\n",
    "    plt.plot(exp1);\n",
    "    plt.plot(est1); plt.show()\n",
    "    plt.figure(figsize=(18,6))\n",
    "    plt.plot(exp2);\n",
    "    plt.plot(est2); plt.show()\n",
    "    \n",
    "    print('error1: {}, error2: {}'.format(np.mean(np.abs(exp1-est1)),np.mean(np.abs(exp2-est2))))\n",
    "    \n",
    "    pass\n",
    "\n",
    "SR_sanity_check()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
